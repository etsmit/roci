{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05630e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7fad836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averager(data,m):\n",
    "\t\"\"\"\n",
    "\taverages data for IQRM\n",
    "\t\"\"\"\n",
    "\tstep1 = np.reshape(data,(data.shape[0],-1,m)) # polarization 1\n",
    "\tstep12 = np.reshape(data,(data.shape[1],-1,m)) # polarization 2\n",
    "\tstep2 = np.nanmean(step1,axis=2) # polarization 1\n",
    "\tstep22 = np.nanmean(step12,axis=2) # polarization 2\n",
    "\tstep3 = []\n",
    "\tstep3.append(np.ndarray.tolist(step2)) # combine\n",
    "\tstep3.append(np.ndarray.tolist(step22))\n",
    "\treturn np.asarray(step3)\n",
    "                  \n",
    "\n",
    "def stdever(data,m):\n",
    "\t\"\"\"\n",
    "\tstandard deviation of data\n",
    "\t\"\"\"\n",
    "\tstep1 = np.reshape(data,(data.shape[0],-1,m)) # polarization 1\n",
    "\tstep12 = np.reshape(data,(data.shape[1],-1,m)) # polarization 2\n",
    "\tstep2 = np.nanstd(step1,axis=2) # polarization 1\n",
    "\tstep22 = np.nanstd(step12,axis=2) # polarization 2\n",
    "\t# combine\n",
    "\tstep3 = []\n",
    "\tstep3.append(np.ndarray.tolist(step2))\n",
    "\tstep3.append(np.ndarray.tolist(step22))\n",
    "\treturn np.asarray(step3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a08f4553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 2., 1., 2.],\n",
       "        [1., 2., 1., 2.]],\n",
       "\n",
       "       [[1., 2., 1., 2.],\n",
       "        [1., 2., 1., 2.]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.asarray([[[1,2],[1,2]], [[1,2],[1,2]]])\n",
    "b = averager(a, 1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "702df2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mitigateRFI_IQRM as mit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7749a37a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (802243222.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    .\\mitigateRFI_IQRM.py\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    ".\\mitigateRFI_IQRM.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a7287c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DescrStatsW',\n",
       " 'GuppiRaw',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'adj_chan_good_data',\n",
       " 'argparse',\n",
       " 'iqrm',\n",
       " 'jit',\n",
       " 'main',\n",
       " 'math',\n",
       " 'noise_filter',\n",
       " 'np',\n",
       " 'os',\n",
       " 'plt',\n",
       " 'prange',\n",
       " 'repl_nans',\n",
       " 'repl_zeros',\n",
       " 'rfi',\n",
       " 'scipy',\n",
       " 'sp',\n",
       " 'statistical_noise_fir',\n",
       " 'sys',\n",
       " 'template_averager',\n",
       " 'template_check_nblocks',\n",
       " 'template_check_outfile',\n",
       " 'template_guppi_format',\n",
       " 'template_infile_mod',\n",
       " 'template_parse',\n",
       " 'template_print_flagstats',\n",
       " 'template_print_header',\n",
       " 'template_save_npy',\n",
       " 'time',\n",
       " 'tqdm']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(mitigateRFI_IQRM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a055eb93",
   "metadata": {},
   "outputs": [
    {
     "ename": "LibRawTooBigError",
     "evalue": "b'Image too big for processing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibRawTooBigError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrawpy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/jetstor/scratch/IQRM_rawdata_results/vegas_60299_76099_B0329+54_0004.0000_IQRM_r5_t3.0_std_b512_mb1_.raw\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43mrawpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kait/lib/python3.9/site-packages/rawpy/__init__.py:20\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(pathOrFile)\u001b[0m\n\u001b[1;32m     18\u001b[0m     d\u001b[38;5;241m.\u001b[39mopen_buffer(pathOrFile)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathOrFile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "File \u001b[0;32mrawpy/_rawpy.pyx:411\u001b[0m, in \u001b[0;36mrawpy._rawpy.RawPy.open_file\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrawpy/_rawpy.pyx:950\u001b[0m, in \u001b[0;36mrawpy._rawpy.RawPy.handle_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mLibRawTooBigError\u001b[0m: b'Image too big for processing'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rawpy\n",
    "\n",
    "path = '/jetstor/scratch/IQRM_rawdata_results/vegas_60299_76099_B0329+54_0004.0000_IQRM_r5_t3.0_std_b512_mb1_.raw'\n",
    "raw = rawpy.imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57d44e22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot load file containing pickled data when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/jetstor/scratch/IQRM_rawdata_results/vegas_60299_76099_B0329+54_0004.0000_IQRM_r5_t3.0_std_b512_mb1_.raw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kait/lib/python3.9/site-packages/numpy/lib/npyio.py:462\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[0;32m--> 462\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load file containing pickled data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    463\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen allow_pickle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(fid, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_kwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "data = np.load('/jetstor/scratch/IQRM_rawdata_results/vegas_60299_76099_B0329+54_0004.0000_IQRM_r5_t3.0_std_b512_mb1_.raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb33b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support functions for mitigateRFI_template.py\n",
    "#These should be used in all mitigateRFI variants\n",
    "\n",
    "import numpy as np\n",
    "import os,sys\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.optimize\n",
    "import scipy.special\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numba import jit,prange\n",
    "\n",
    "\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "\n",
    "\n",
    "\n",
    "#get the template arguments\n",
    "def template_parse(parser):\n",
    "\n",
    "\t#input file\n",
    "\tparser.add_argument('-i',dest='infile',type=str,required=True,help='String. Required. Name of input filename. Automatically pulls from standard data directory. If leading \"/\" given, pulls from given directory')\n",
    "\n",
    "\t#replacement method\n",
    "\tparser.add_argument('-r',dest='method',type=str,choices=['zeros','previousgood','stats','nans'], required=True,default='zeros',help='String. Required. Replacement method of flagged data in output raw data file. Can be \"zeros\",\"previousgood\", nans or \"stats\"')\n",
    "\n",
    "\t#write out a whole new raw file or just get SK/accumulated spectra results\n",
    "\tparser.add_argument('-newfile',dest='output_bool',type=bool,default=True,help='Copy the original data and output a replaced datafile. Default True. Change to False to not write out a whole new GUPPI file')\n",
    "\n",
    "\t#custom filename tag (for adding info not already covered in lines 187\n",
    "\tparser.add_argument('-cust',dest='cust',type=str,default='',help='custom tag to add to end of filename')\n",
    "\n",
    "\t#using multiple blocks at once to help stats replacement\n",
    "\tparser.add_argument('-mult',dest='mb',type=int,default=1,help='load multiple blocks at once to help with stats/prevgood replacement')\n",
    "\n",
    "    #using multiple blocks at once to help stats replacement\n",
    "\tparser.add_argument('-union',dest='union',type=int,default=1,help='Combine the polarizations in the flagging step. Default 1.')\n",
    "\n",
    "\t#parse input variables\n",
    "\targs = parser.parse_args()\n",
    "\tinfile = args.infile\n",
    "\tmethod = args.method\n",
    "\trawdata = args.rawdata\n",
    "\tcust = args.cust\n",
    "\tmb = args.mb\n",
    "\toutput_bool = args.output_bool\n",
    "\tcombine_flag_pols = args.union\n",
    "\treturn infile, method, rawdata, output_bool, cust, mb, combine_flag_pols\n",
    "\n",
    "\n",
    "#modify input filename to include the right directory\n",
    "def template_infile_mod(infile,in_dir):\n",
    "\t#input file\n",
    "\t#pulls from the raw data directory if full path not given\n",
    "\tif infile[0] != '/':\n",
    "\t\tinfile = in_dir + infile\n",
    "\telse:\n",
    "\t\tin_dir = infile[:infile.rfind('/')+1]\n",
    "\t\t#infile = infile[infile.rfind('/')+1:]\n",
    "\n",
    "\tif infile[-4:] != '.raw':\n",
    "\t\tinput(\"WARNING input filename doesn't end in '.raw'. Are you sure you want to use this file?\")\n",
    "\treturn infile\n",
    "\n",
    "\n",
    "#check that the outfile doesn't already exist, ask for overwrite confirmation \n",
    "def template_check_outfile(infile,outfile):\n",
    "\tprint('Saving replaced data to '+outfile)\n",
    "\tprint(infile,outfile)\n",
    "\tif os.path.isfile(outfile):\n",
    "\t\tyn = input((f\"The output file {outfile} already exists. Press 'y' to start with a fresh copy of the input file, 'n' to continue overwriting what's already there, or ctrl-c to end the script\"))\n",
    "\t\tif yn=='y':\n",
    "\t\t\tprint('Copying infile to outfile...')\n",
    "\t\t\tos.system('cp '+infile+' '+outfile)\n",
    "\telse:\n",
    "\t\tos.system('cp '+infile+' '+outfile)\n",
    "\n",
    "#check that the number of blocks loaded at once is a divisible integer of the number of blocks in the file\n",
    "def template_check_nblocks(rawFile,mb):\n",
    "\tnumblocks = rawFile.find_n_data_blocks()\n",
    "\tprint('File has '+str(numblocks)+' data blocks')\n",
    "\t#check for mismatched amount of blocks\n",
    "\tmismatch = numblocks % mb\n",
    "\tif (mismatch != 0):\n",
    "\t\tprint(f'There are {numblocks} blocks and you set -mb {mb}, pick a divisible integer')\n",
    "\t\tsys.exit()\n",
    "\n",
    "#read the first block's header\n",
    "def template_print_header(rawFile):\n",
    "\theader,headersize = rawFile.read_header()\n",
    "\tprint('Header size: {} bytes'.format(headersize))\n",
    "\tfor line in header:\n",
    "\t\tprint(line+':  '+str(header[line]))\n",
    "\treturn headersize\n",
    "\n",
    "#save numpy files\n",
    "def template_save_npy(data,block,npy_base):\n",
    "\tblock_fname = str(block).zfill(3)\n",
    "\tsave_fname = npybase+'_block'+block_fname+'.npy'\n",
    "\tnp.save(save_fname,data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#=======================\n",
    "#Replacement\n",
    "#=======================\n",
    "\n",
    "\n",
    "def repl_zeros(a,f):\n",
    "\t\"\"\"\n",
    "\tReplace flagged data with 0's.\n",
    "\n",
    "\tParameters\n",
    "\t-----------\n",
    "\ta : ndarray\n",
    "\t\t3-dimensional array of power values. Shape (Num Channels , Num Raw Spectra , Npol)\n",
    "\tf : ndarray\n",
    "\t\t3-dimensional array of flags. 1=RFI detected, 0 no RFI. Shape (Num Channels , Num Raw Spectra , Npol), should be same shape as a.\n",
    "\t\n",
    "\t\n",
    "\tReturns\n",
    "\t-----------\n",
    "\tout : ndarray\n",
    "\t\t3-dimensional array of power values with flagged data replaced. Shape (Num Channels , Num Raw Spectra , Npol)\n",
    "\t\"\"\"\n",
    "\t#these will get cast to 0 in the next step, the 1e-4 is to stop any possible issues with log10\n",
    "\ta[f==1]=1e-4 + 1e-4*1.j\n",
    "\treturn a\n",
    "\n",
    "\n",
    "\n",
    "def repl_nans(a,f):\n",
    "\t\"\"\"\n",
    "\tReplace flagged data with nans.\n",
    "\n",
    "\tParameters\n",
    "\t-----------\n",
    "\ta : ndarray\n",
    "\t\t3-dimensional array of power values. Shape (Num Channels , Num Raw Spectra , Npol)\n",
    "\tf : ndarray\n",
    "\t\t3-dimensional array of flags. 1=RFI detected, 0 no RFI. Shape (Num Channels , Num Raw Spectra , Npol), should be same shape as a.\n",
    "\t\n",
    "\t\n",
    "\tReturns\n",
    "\t-----------\n",
    "\tout : ndarray\n",
    "\t\t3-dimensional array of power values with flagged data replaced. Shape (Num Channels , Num Raw Spectra , Npol)\n",
    "\t\"\"\"\n",
    "\t#these will get cast to 0 in the next step, the 1e-4 is to stop any possible issues with log10\n",
    "\ta[f==1]=np.nan\n",
    "\treturn a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#replace with statistical noise\n",
    "# @jit(parallel=True)\n",
    "def statistical_noise_fir(a,f,ts_factor):\n",
    "\t\"\"\"\n",
    "\tReplace flagged data with statistical noise.\n",
    "\t- fir version that adds a fir in the noise\n",
    "\tParameters\n",
    "\t-----------\n",
    "\ta : ndarray\n",
    "\t\t3-dimensional array of power values. Shape (Num Channels , Num Raw Spectra , Npol)\n",
    "\tf : ndarray\n",
    "\t\t3-dimensional array of flags. 1=RFI detected, 0 no RFI. Shape (Num Channels , Num Raw Spectra , Npol), should be same shape as a.\n",
    "\n",
    "\t\n",
    "\tReturns\n",
    "\t-----------\n",
    "\tout : np.random.normal(0,1,size=2048)ndarray\n",
    "\t\t3-dimensional array of power values with flagged data replaced. Shape (Num Channels , Num Raw Spectra , Npol)\n",
    "\t\"\"\"\n",
    "\tprint('stats....')\n",
    "\t#find correct PFB coefficents\n",
    "\tnchan = str(f.shape[0]).zfill(4)\n",
    "\t#print(nchan,type(nchan))\t\n",
    "\thfile = '/users/esmith/RFI_MIT/PFBcoeffs/c0800x'+nchan+'_x14_7_24t_095binw_get_pfb_coeffs_h.npy'\n",
    "\tprint(f'loading {hfile} for FIR coefficients')\n",
    "\th = np.load(hfile)\n",
    "\tdec = h[::2*f.shape[0]]\n",
    "\tif ts_factor!=1:\n",
    "\t\tpulse = np.ones((1,ts_factor,1))\n",
    "\t\tf = np.kron(f,pulse)\n",
    "\tfor pol in prange(f.shape[2]):\n",
    "\t\tfor i in prange(f.shape[0]):\n",
    "\n",
    "\t\t\t\t#for tb in prange(f.shape[1]):\n",
    "\t\t\t\t#\tif f[i,tb,pol] == 1:\n",
    "\n",
    "\t\t\t\t#\t\tSK_M = ts_factor\n",
    "                #        pulse = np.ones(ts_factor)\n",
    "                        \n",
    " \n",
    "\t\t\t\t#\t\tstd_real,std_imag = adj_chan_good_data(a[:,tb*SK_M:(tb+1)*SK_M,pol],f[:,tb,pol],i)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t#\t\t(a[i,tb*SK_M:(tb+1)*SK_M,pol].real) = noise_filter(0,std_real,SK_M,dec)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t#\t\t(a[i,tb*SK_M:(tb+1)*SK_M,pol].imag) = noise_filter(0,std_imag,SK_M,dec)\n",
    "\n",
    "\n",
    "\t\t\t#else:\n",
    "\t\t\tbad_data_size = np.count_nonzero(f[i,:,pol])\n",
    "\t\t\tif bad_data_size > 0:\n",
    "\t\t\t\tstd_real,std_imag = adj_chan_good_data(a[:,:,pol],f[:,:,pol],i)\n",
    "\n",
    "\t\t\t\ta[i,:,pol].real[f[i,:,pol] == 1] = noise_filter(0,std_real,bad_data_size,dec)  \n",
    "\t\t\t\ta[i,:,pol].imag[f[i,:,pol] == 1] = noise_filter(0,std_imag,bad_data_size,dec)\n",
    "\treturn a\n",
    "\n",
    "\n",
    "\n",
    "def adj_chan_good_data(a,f,c):\n",
    "\t\"\"\"\n",
    "\tReturn mean/std derived from unflagged data in adjacent channels \n",
    "\tParameters\n",
    "\t-----------\n",
    "\ta : ndarray\n",
    "\t\t3-dimensional array of original power values. Shape (Num Channels , Num Raw Spectra , Npol)\n",
    "\tf : ndarray\n",
    "\t\t3-dimensional array of flags. 1=RFI detected, 0 no RFI. Shape (Num Channels , Num Raw Spectra , Npol), should be same shape as a.\n",
    "\tc : int\n",
    "\t\tChannel of interest\n",
    "\t\n",
    "\tReturns\n",
    "\t-----------\n",
    "\tstd_real : float\t\t\n",
    "\t\tstandard deviation of unflagged real data\n",
    "\tstd_imag : float\n",
    "\t\tstandard deviation of unflagged imaginary data\n",
    "\t\"\"\"\n",
    "\tif len(f.shape) == 1:\n",
    "\t\tf = np.expand_dims(f,axis=1)\n",
    "\t#num_iter = num_iter\n",
    "\t#failed = failed\n",
    "\t#define adjacent channels and clear ones that don't exist (neg chans, too high)\n",
    "\t#adj_chans = [c-3,c-2,c-1,c,c+1,c+2,c+3]\n",
    "\tadj_chans = [c-1,c,c+1]\n",
    "\tadj_chans = [i for i in adj_chans if i>=0]\n",
    "\tadj_chans = [i for i in adj_chans if i<a.shape[0]]\n",
    "\n",
    "\tadj_chans = np.array(adj_chans,dtype=np.uint32)\n",
    "\n",
    "\t#set up array of unflagged data and populate it with any unflagged data from adj_chans channels\n",
    "\tgood_data=np.empty(0,dtype=np.complex64)\n",
    "\tgood_data = np.append(good_data,a[adj_chans,:][f[adj_chans,:] == 0])\n",
    "\n",
    "\tadj=1\n",
    "\t#keep looking for data in adjacent channels if good_data empty\n",
    "\tfailed = 0    \n",
    "\twhile (good_data.size==0):\n",
    "\t\tadj += 1\n",
    "\t\tif (c-adj >= 0):\n",
    "\t\t\tgood_data = np.append(good_data,a[c-adj,:][f[c-adj,:] == 0])\n",
    "\t\tif (c+adj < a.shape[0]):\n",
    "\t\t\tgood_data = np.append(good_data,a[c+adj,:][f[c+adj,:] == 0])\n",
    "\t\t#if we go 8% of the spectrum away, give up and give flagged data from same channel\n",
    "\t\tfailed += 1\n",
    "\t\tif adj >= int(a.shape[0]*0.08):\n",
    "\t\t\tgood_data = a[c,:]\n",
    "\t\t\tbreak\n",
    "\n",
    "\tstd_real = np.std(good_data.real)\n",
    "\tstd_imag = np.std(good_data.imag)\n",
    "\n",
    "\treturn std_real,std_imag\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def noise_filter(ave,std,msk,dec):\n",
    "\t\"\"\"\n",
    "\tCreate gaussian noise filtered by the correct PFB coefficients to mimic the VEGAS coarse channel SEFD\n",
    "\tParameters\n",
    "\t-----------\n",
    "\tave : float\n",
    "\t\taverage/center value of intended noise \n",
    "\tstd : float\n",
    "\t\tstandard deviation of noise (before FIR)\n",
    "\tmsk : int\n",
    "\t\tM parameter of SK equation. Is also the amount of new data points to generate\n",
    "\tdec : decimated coefficient array to apply in FIR\n",
    "\t\n",
    "\tReturns\n",
    "\t-----------\n",
    "\tout_filtered : ndarray\n",
    "\t\t1-dimensional string of filtered gaussian noise to inject back over masked data\n",
    "\t\"\"\"\n",
    "\t#make correctly scaled noise\n",
    "\tout = np.random.normal(ave,std,msk)\n",
    "\t#do FIR\n",
    "\tout_filtered = np.convolve(dec,out,mode='same')\n",
    "\treturn out_filtered\n",
    "\n",
    "\n",
    "\n",
    "def template_guppi_format(a):\n",
    "\t\"\"\"\n",
    "\ttakes array of np.complex64,ravels it and outputs as 1D array of signed 8 bit integers \n",
    "\tordered x1r,x1i,y1r,y1i,x2r,x2i,y2r,....\n",
    "\tParameters\n",
    "\t-----------\n",
    "\ta : ndarray\n",
    "\t\t3-dimensional array of original power values. Shape (Num Channels , Num Raw Spectra , Npol)\n",
    "\tReturns\n",
    "\t-----------\n",
    "\tout_arr : ndarray\n",
    "\t\t1-dimensional array of values to be written back to the copied data file\n",
    "\t\"\"\"\n",
    "\t#init output\n",
    "\tout_arr = np.empty(shape=2*a.size,dtype=np.int8)\n",
    "\t#get real values, ravel, cast to int8\n",
    "\tarav = a.ravel()\n",
    "\ta_real = np.clip(np.floor(arav.real),-128,127).astype(np.int8)\n",
    "\t#get imag values, ravel, cast to int8\n",
    "\ta_imag = np.clip(np.floor(arav.imag),-128,127).astype(np.int8)\n",
    "\t#interleave\n",
    "\tout_arr[::2] = a_real\n",
    "\tout_arr[1::2] = a_imag\n",
    "\treturn out_arr\n",
    "\n",
    "\n",
    "def template_print_flagstats(flags_all):\n",
    "\n",
    "\ttot_points = flags_all[:,:,1].size\n",
    "\tflagged_pts_p1 = np.count_nonzero(flags_all[:,:,0])\n",
    "\tflagged_pts_p2 = np.count_nonzero(flags_all[:,:,1])\n",
    "\n",
    "#print(f'Pol0: {flagged_pts_p2} datapoints were flagged out of {tot_points}')\n",
    "\tflagged_percent = (float(flagged_pts_p1)/tot_points)*100\n",
    "\tprint(f'Pol0: {np.mean(flags_all[:,:,0])}% of data outside acceptable ranges')\n",
    "\n",
    "#print(f'Pol1: {flagged_pts_p2} datapoints were flagged out of {tot_points}')\n",
    "\tflagged_percent = (float(flagged_pts_p2)/tot_points)*100\n",
    "\tprint(f'Pol1: {np.mean(flags_all[:,:,0])}% of data outside acceptable ranges')\n",
    "\n",
    "\tflags_all[:,:,0][flags_all[:,:,1]==1]=1\n",
    "\tprint(f'Union of flags: {np.mean(flags_all[:,:,0])}% of data flagged')\n",
    "\n",
    "\n",
    "# \ttot_points = flags_all[:,:,1].size\n",
    "# \tflagged_pts_p1 = np.count_nonzero(flags_all[:,:,0])\n",
    "# \tflagged_pts_p2 = np.count_nonzero(flags_all[:,:,1])\n",
    "\n",
    "# \t#print(f'Pol0: {flagged_pts_p2} datapoints were flagged out of {tot_points}')\n",
    "# \tflagged_percent = (float(flagged_pts_p1)/tot_points)*100\n",
    "# \tprint(f'Pol0: {np.mean(flags_all[:,:,0])}% of data outside acceptable ranges')\n",
    "\n",
    "# \t#print(f'Pol1: {flagged_pts_p2} datapoints were flagged out of {tot_points}')\n",
    "# \tflagged_percent = (float(flagged_pts_p2)/tot_points)*100\n",
    "# \tprint(f'Pol1: {np.mean(flags_all[:,:,0])}% of data outside acceptable ranges')\n",
    "\n",
    "# \tflags_all[:,:,0][flags_all[:,:,1]==1]=1\n",
    "# \tprint(f'Union of flags: {np.mean(flags_all[:,:,0])}% of data flagged')\n",
    "\n",
    "def template_averager(data,m):\n",
    "\tstep1 = np.reshape(data, (data.shape[0],-1,m))\n",
    "\tstep2 = np.mean(step1,axis=2)\n",
    "\treturn step2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716368f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mitigateRFI\n",
    "\n",
    "\n",
    "Template for RFI mitigation. Put your own algorithm in. See below for instructions.\n",
    "\n",
    "\n",
    "Use instructions:\n",
    "\n",
    " - psrenv preferred, or\n",
    " - /users/esmith/.conda/envs/py365 conda environment on green bank machine\n",
    " - type ' -h' to see help message\n",
    "\n",
    "Inputs\n",
    "------------\n",
    "  -h, --help            show this help message and exit\n",
    "  -i INFILE             String. Required. Name of input filename.\n",
    "                        Automatically pulls from standard data directory. If\n",
    "                        leading \"/\" given, pulls from given directory\n",
    "  -rfi {SKurtosis,SEntropy,IQRM}\n",
    "                        String. Required. RFI detection method desired.\n",
    "  -m SK_M               Integer. Required. \"M\" in the SK equation. Number of\n",
    "                        data points to perform SK on at once/average together\n",
    "                        for spectrogram. ex. 1032704 (length of each block)\n",
    "                        has prime divisors (2**9) and 2017. Default 512.\n",
    "  -r {zeros,previousgood,stats}\n",
    "                        String. Required. Replacement method of flagged data\n",
    "                        in output raw data file. Can be\n",
    "                        \"zeros\",\"previousgood\", or \"stats\"\n",
    "  -s SIGMA              Float. Sigma thresholding value. Default of 3.0 gives\n",
    "                        probability of false alarm 0.001349\n",
    "  -n N                  Integer. Number of inside accumulations, \"N\" in the SK\n",
    "                        equation. Default 1.\n",
    "  -v VEGAS_DIR          If inputting a VEGAS spectral line mode file, enter\n",
    "                        AGBT19B_335 session number (1/2) and bank (C/D) ex\n",
    "                        \"1D\".\n",
    "  -newfile OUTPUT_BOOL  Copy the original data and output a replaced datafile.\n",
    "                        Default True. Change to False to not write out a whole\n",
    "                        new GUPPI file\n",
    "  -d D                  Float. Shape parameter d. Default 1, but is different\n",
    "                        in the case of low-bit quantization. Can be found (i\n",
    "                        think) by running SK and changing d to be 1/x, where x\n",
    "                        is the center of the SK value distribution.\n",
    "  -npy RAWDATA          Boolean. True to save raw data to npy files. This is\n",
    "                        storage intensive and unnecessary since blimpy.\n",
    "                        Default is False\n",
    "  -ms multiscale SK     String. Multiscale SK bin size. \n",
    "                        2 ints : Channel size / Time size, ex '-ms 42' Default '11'\n",
    "  -mb mb\t\tFor loading multiple blocks at once. Helps with finding good\n",
    "                        data for replacing flagged data, but can balloon RAM usage. \n",
    "                        Default 1.\n",
    "\n",
    "#Assumes two polarizations\n",
    "\n",
    "python mitigateRFI_IQRM.py -i vegas_60299_76099_B0329+54_0004.0000.raw -r stats -IQRM_datatype power\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.optimize\n",
    "import scipy.special\n",
    "import math as math\n",
    "\n",
    "import argparse\n",
    "\n",
    "import time\n",
    "\n",
    "from blimpy import GuppiRaw\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import iqrm\n",
    "\n",
    "import RFI_detection as rfi\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def mitigateRFI_IQRM(*args):\n",
    "#--------------------------------------\n",
    "# Inputs\n",
    "#--------------------------------------\n",
    "\n",
    "\n",
    "    #directories of interest\n",
    "    in_dir = '/data/rfimit/unmitigated/rawdata/'#leibniz only\n",
    "    out_dir = '/data/scratch/IQRMresults/'#leibniz only\n",
    "    jstor_dir = '/jetstor/scratch/IQRM_rawdata_results/'#leibniz only\n",
    "\n",
    "    #ID string of your RFI mitigation algorithm, for filenames and input parameters\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"\"\"function description\"\"\")\n",
    "\n",
    "    #input file\n",
    "    parser.add_argument('-i',dest='infile',type=str,required=True,help='String. Required. Name of input filename. Automatically pulls from standard data directory. If leading \"/\" given, pulls from given directory')\n",
    "\n",
    "    #replacement method\n",
    "    parser.add_argument('-r',dest='method',type=str,choices=['zeros','previousgood','stats','nans'], required=True,default='zeros',help='String. Required. Replacement method of flagged data in output raw data file. Can be \"zeros\",\"previousgood\", nans or \"stats\"')\n",
    "\n",
    "    #write out a whole new raw file or just get SK/accumulated spectra results\n",
    "    parser.add_argument('-newfile',dest='output_bool',type=bool,default=True,help='Copy the original data and output a replaced datafile. Default True. Change to False to not write out a whole new GUPPI file')\n",
    "\n",
    "    #custom filename tag (for adding info not already covered in lines 187\n",
    "    parser.add_argument('-cust',dest='cust',type=str,default='',help='custom tag to add to end of filename')\n",
    "\n",
    "    #using multiple blocks at once to help stats replacement\n",
    "    parser.add_argument('-mult',dest='mb',type=int,default=1,help='load multiple blocks at once to help with stats/prevgood replacement')\n",
    "\n",
    "    #using multiple blocks at once to help stats replacement\n",
    "    parser.add_argument('-union',dest='union',type=int,default=1,help='Combine the polarizations in the flagging step. Default 1.')\n",
    "\n",
    "\n",
    "    #=================================================\n",
    "    # * * * * * * * * * * * * * *\n",
    "\n",
    "    #ID string of your RFI mitigation algorithm, for filenames and input parameters\n",
    "    IDstr = 'IQRM'\n",
    "\n",
    "    #parse the input arguments specific to your RFI mitigation algorithm\n",
    "\n",
    "    #example, for SK:\n",
    "\n",
    "    # radius\n",
    "    parser.add_argument('-IQRM_radius',dest='IQRM_radius',type=int,required=False,default=5,help='Integer. Determines the outlier status of a point by using the number of elements to its furthest neighbor. Default 5.')\n",
    "\n",
    "    # threshold\n",
    "    parser.add_argument('-IQRM_threshold',dest='IQRM_threshold',type=float,required=False,default=3.0,help=\"Float. Controls the bounds for the otlier status with a number of Gaussian standard deviations. Default 3.0.\")\n",
    "\n",
    "    # datatype ADD MORE CHOICES\n",
    "    parser.add_argument('-IQRM_datatype',dest='IQRM_datatype',type=str, choices=['power', 'std'], required=False,default='power',help=\"String. Options: 'std' 'power'. Determines the type of data that is input into the IQRM function. Default 'power'.\")\n",
    "\n",
    "    # breakdown\n",
    "    parser.add_argument('-IQRM_breakdown',dest='IQRM_breakdown',type=int,required=False,default=512,help=\"Integer. Recommended if using the standard deviation of the data as an input to IQRM. Determines the breakdown of the groups when calculating the stdev. Default 512.\")\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    IQRM_radius = args.IQRM_radius\n",
    "    IQRM_threshold = args.IQRM_threshold\n",
    "    IQRM_datatype = args.IQRM_datatype\n",
    "    IQRM_breakdown = args.IQRM_breakdown\n",
    "\n",
    "    # * * * * * * * * * * * * * *\n",
    "    #=================================================\n",
    "\n",
    "    #load in the global arguments\n",
    "\n",
    "    #infile, method, rawdata, output_bool, cust, mb, combine_flag_pols = template_parse(parser)\n",
    "\n",
    "    infile = args.infile\n",
    "    method = args.method\n",
    "    # rawdata = args.rawdata\n",
    "    cust = args.cust\n",
    "    mb = args.mb\n",
    "    output_bool = args.output_bool\n",
    "    combine_flag_pols = args.union\n",
    "\n",
    "    #check infile, modify it to include in_dir if we don't give a full path to the file\n",
    "    infile = template_infile_mod(infile,in_dir)\n",
    "\n",
    "\n",
    "    #=================================================\n",
    "    # * * * * * * * * * * * * * *\n",
    "\n",
    "    #pattern for your parameters specific to the RFI\n",
    "    #example for SK:\n",
    "    if IQRM_datatype == 'std':\n",
    "        outfile_pattern = f\"r{IQRM_radius}_t{IQRM_threshold}_{IQRM_datatype}_b{IQRM_breakdown}\"\n",
    "    else:\n",
    "        outfile_pattern = f\"r{IQRM_radius}_t{IQRM_threshold}_{IQRM_datatype}\"\n",
    "\n",
    "\n",
    "    # any separate results filenames you need, in addition to the flags filename, put them here\n",
    "    npybase = out_dir+'npy_results/'+infile[len(in_dir):-4]\n",
    "\n",
    "\n",
    "    avg_pre_filename = f\"{npybase}_avg_pre_{IDstr}_{outfile_pattern}_{cust}.npy\"\n",
    "    avg_post_filename = f\"{npybase}_avg_post_{IDstr}_{outfile_pattern}_{cust}.npy\"\n",
    "    spost_filename = f\"{npybase}_spost_{IDstr}_{outfile_pattern}_{cust}.npy\"\n",
    "\n",
    "\n",
    "    flags_filename = f\"{npybase}_flags_{IDstr}_{outfile_pattern}_{cust}.npy\"\n",
    "\n",
    "    #And then any one-off calculations at the beginning of the script\n",
    "\n",
    "    #threshold calc from sigma\n",
    "    IQRM_lag = iqrm.core.genlags(IQRM_radius, geofactor=1.5)\n",
    "    print('integer lags, k: {}'.format(IQRM_lag))\n",
    "\n",
    "    #calculate % flagged\n",
    "    # print('Calculating flagged percent...')\n",
    "    # flagged = np.mean(flag_chunk)\n",
    "    # print('Flagged: '+str(flagged)+'%')\n",
    "\n",
    "    # #calculate ms thresholds\n",
    "    # ms_lt, ms_ut = SK_thresholds(SK_M*ms0*ms1, N = n, d = d, p = SK_p)\n",
    "    # print('MS Upper Threshold: '+str(ms_ut))\n",
    "    # print('MS Lower Threshold: '+str(ms_lt))\n",
    "\n",
    "\n",
    "    # * * * * * * * * * * * * * *\n",
    "    #=================================================\n",
    "\n",
    "    #output raw data filename\n",
    "    outfile = f\"{jstor_dir}{infile[len(in_dir):-4]}_{IDstr}_{outfile_pattern}_mb{mb}_{cust}{infile[-4:]}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # if rawdata:\n",
    "    # \tprint('Saving raw data to npy block style files')\n",
    "\n",
    "\n",
    "    #--------------------------------------\n",
    "    # Fun\n",
    "    #--------------------------------------\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    if output_bool:\n",
    "        template_check_outfile(infile,outfile)\n",
    "        out_rawFile = open(outfile,'rb+')\n",
    "\n",
    "    #load file and copy\n",
    "    print('Opening file: '+infile)\n",
    "    rawFile = GuppiRaw(infile)\n",
    "\n",
    "    numblocks = rawFile.find_n_data_blocks()\n",
    "    template_check_nblocks(rawFile,mb)\n",
    "\n",
    "    flagged_pts_p1 = 0\n",
    "    flagged_pts_p2 = 0\n",
    "    for block in range(numblocks//mb):\n",
    "        print('------------------------------------------')\n",
    "        print(f'Block: {(block*mb)+1}/{numblocks}')\n",
    "\n",
    "\n",
    "        #print header for the first block\n",
    "        if block == 0:\n",
    "            headersize = template_print_header(rawFile)\n",
    "\n",
    "\n",
    "        #loading multiple blocks at once?\t\n",
    "        for mb_i in range(mb):\n",
    "            if mb_i==0:\n",
    "                header,data = rawFile.read_next_data_block()\n",
    "                data = np.copy(data)\n",
    "                d1s = data.shape[1]\n",
    "            else:\n",
    "                h2,d2 = rawFile.read_next_data_block()\n",
    "                data = np.append(data,np.copy(d2),axis=1)\n",
    "\n",
    "        #find data shape\n",
    "        num_coarsechan = data.shape[0]\n",
    "        num_timesamples= data.shape[1]\n",
    "        num_pol = data.shape[2]\n",
    "        print('Data shape: {} || block size: {}'.format(data.shape,data.nbytes))\n",
    "\n",
    "        #save raw data?\n",
    "    # \tif rawdata:\n",
    "    # \t\ttemplate_save_npy(data,block,npy_base)\n",
    "\n",
    "\n",
    "    #=================================================\n",
    "    # * * * * * * * * * * * * * *\n",
    "\n",
    "\n",
    "        #======================================\n",
    "        #insert RFI detection of choice\n",
    "        #\n",
    "        #you currently have:\n",
    "        #\n",
    "        # data : 3D array of data from a single GUPPI/VPM block 'block'\n",
    "        #\tindex [Channel,Spectrum,Polarization]\n",
    "        #\tthese are np.complex64 complex channelized voltages\n",
    "        #\n",
    "        #\tAs well as any input parameters you specified above\n",
    "        #\n",
    "        #you need to output from this section:\n",
    "        #\n",
    "        # flag_chunk : 3D array of flags that correspond to the flags for this block\n",
    "        #\tshape can be the same as data or scrunched in the time axis\n",
    "        #\t(tscrunched flags are fast, so do that if you can)\n",
    "        #\tvalues follow the pattern\n",
    "        #\t0: unflagged || 1: flagged\n",
    "        #\n",
    "        # any intermediate output arrays \n",
    "        #\tdetection metrics, averaged spectra, etc. Make sure\n",
    "        #\tto fill them block-by-block using the if/else below\n",
    "        #\tand write them to disk at the end of the script\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\tIdeally, your RFI code goes in RFI_detection_routines.py\n",
    "        #\t and you simply place the function calls here.\n",
    "        #\n",
    "        #======================================\n",
    "    # is this indented?\n",
    "    # average\n",
    "        if IQRM_datatype == 'power':\n",
    "            flag_chunk, avg_pre = rfi.iqrm_power(data, IQRM_radius, IQRM_threshold)\n",
    "\n",
    "        # standard dev\n",
    "        else:# if IQRM_datatype == 'std': \n",
    "            flag_chunk, avg_pre = rfi.iqrm_std(data, IQRM_radius, IQRM_threshold, IQRM_breakdown)\n",
    "\n",
    "\n",
    "\n",
    "    # else:\n",
    "    #     return #throw some error?\n",
    "\n",
    "\n",
    "\n",
    "        #if you are making any intermediate numpy arrays (in addition to the flagging array), fill them here:\n",
    "\n",
    "        if (block==0):\n",
    "\n",
    "            flags_all = flag_chunk.astype(np.int8)\n",
    "        else:\n",
    "\n",
    "            flags_all = np.concatenate((flags_all,flag_chunk.astype(np.int8)),axis=1)\n",
    "\n",
    "        # these will be written to disk at the end of the script\n",
    "\n",
    "    # * * * * * * * * * * * * * *\n",
    "    #=================================================\n",
    "\n",
    "        #record flagging % in both polarizations\n",
    "        flagged_pts_p1 += (1./numblocks) * ((100.*np.count_nonzero(flag_chunk[:,:,0]))/flag_chunk[:,:,0].size)\n",
    "        flagged_pts_p2 += (1./numblocks) * ((100.*np.count_nonzero(flag_chunk[:,:,1]))/flag_chunk[:,:,1].size)\n",
    "\n",
    "\n",
    "        #now flag shape is (chan,spectra,pol)\n",
    "        #apply union of flags between the pols\n",
    "        if combine_flag_pols:\n",
    "            flag_chunk[:,:,0][flag_chunk[:,:,1]==1]=1\n",
    "            flag_chunk[:,:,1][flag_chunk[:,:,0]==1]=1\n",
    "\n",
    "        ts_factor = data.shape[1] // flag_chunk.shape[1]\n",
    "        if (data.shape[1] % flag_chunk.shape[1] != 0):\n",
    "            print('Flag chunk size is incompatible with block size')\n",
    "            sys.exit()\n",
    "\n",
    "\n",
    "        if method == 'zeros':\n",
    "            #replace data with zeros\n",
    "            data = repl_zeros(data,flag_chunk)\n",
    "\n",
    "        if method == 'previousgood':\n",
    "            #replace data with previous (or next) good\n",
    "            data = previous_good(data,flag_chunk,ts_factor)\n",
    "\n",
    "        if method == 'stats':\n",
    "            #replace data with statistical noise derived from good datapoints\n",
    "            data = statistical_noise_fir(data,flag_chunk,ts_factor)\n",
    "\n",
    "        spost = template_averager(data,512)\n",
    "        if (block==0):\n",
    "            spost_all = spost\n",
    "        else:\n",
    "            spost_all = np.concatenate((spost_all,spost),axis=1)\n",
    "\n",
    "        #Write back to copied raw file\n",
    "        if output_bool:\n",
    "            print('Re-formatting data and writing back to file...')\n",
    "            for mb_i in range(mb):\n",
    "                out_rawFile.seek(headersize,1)\n",
    "                d1 = template_guppi_format(data[:,d1s*mb_i:d1s*(mb_i+1),:])\n",
    "                out_rawFile.write(d1.tostring())\n",
    "        np.save(flags_filename,flags_all)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #save flags results\n",
    "    np.save(flags_filename,flags_all)\n",
    "    print(f'{flags_all.shape} Flags file saved to {flags_filename}')\n",
    "\n",
    "    #save spost results\n",
    "    np.save(spost_filename,spost_all)\n",
    "    print(f'{spost_all.shape} spost file saved to {spost_filename}')\n",
    "\n",
    "\n",
    "    #=================================================\n",
    "    # * * * * * * * * * * * * * *\n",
    "    # avg_post = averager(np.abs(out_rawFile)**2,512)\n",
    "\n",
    "    #Any intermediate numpy arrays can be written out here, in addition to the flags array above\n",
    "\n",
    "    np.save(avg_pre_filename, avg_pre)\n",
    "    # np.save(avg_post_filename, avg_post)\n",
    "    # * * * * * * * * * * * * * *\n",
    "    #=================================================\n",
    "\n",
    "\n",
    "    #tally up flags\n",
    "\n",
    "    template_print_flagstats(flags_all)\n",
    "\n",
    "\n",
    "    #clean up and end\n",
    "\n",
    "    print('Saved replaced data to '+outfile)\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed = float(end_time-start_time)/60 \n",
    "\n",
    "    print('Program took {} minutes'.format(elapsed))\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mitigateRFI_IQRM(sys.argv)\n",
    "\n",
    "\n",
    "#test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33535f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os,sys\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from RFI_support import *\n",
    "\n",
    "from numba import jit,prange\n",
    "import iqrm\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------\n",
    "# 1 . Functions for performing SK\n",
    "#---------------------------------------------------------\n",
    "\n",
    "#Compute SK on a 2D array of power values\n",
    "\n",
    "@jit(parallel=True)\n",
    "def SK_EST(a,m,n=1,d=1):\n",
    "\t\"\"\"\n",
    "\tCompute SK on a 2D array of power values.\n",
    "\n",
    "\tParameters\n",
    "\t-----------\n",
    "\ta : ndarray\n",
    "\t\t2-dimensional array of power values. Shape (Num Channels , Num Raw Spectra)\n",
    "\tn : int\n",
    "\t\tinteger value of N in the SK function. Inside accumulations of spectra.\n",
    "\tm : int\n",
    "\t\tinteger value of M in the SK function. Outside accumulations of spectra.\n",
    "\td : float\n",
    "\t\tshape parameter d in the SK function. Usually 1 but can be empirically determined.\n",
    "\t\n",
    "\tReturns\n",
    "\t-----------\n",
    "\tout : ndarray\n",
    "\t\tSpectrum of SK values.\n",
    "\t\"\"\"\n",
    "\n",
    "\t#make s1 and s2 as defined by whiteboard (by 2010b Nita paper)\n",
    "\ta = a[:,:m]*n\n",
    "\tsum1=np.sum(a,axis=1)\n",
    "\tsum2=np.sum(a**2,axis=1)\n",
    "\tsk_est = ((m*n*d+1)/(m-1))*(((m*sum2)/(sum1**2))-1)                     \n",
    "\treturn sk_est\n",
    "\n",
    "\n",
    "@jit(parallel=True)\n",
    "def SK_EST_alt(s1,s2,m,n=1,d=1):\n",
    "\t\"\"\"\n",
    "\tCompute SK on a 2D array of power values, using s1 and s2 given instead of data\n",
    "\n",
    "\tParameters\n",
    "\t-----------\n",
    "\n",
    "\tn : int\n",
    "\t\tinteger value of N in the SK function. Inside accumulations of spectra.\n",
    "\tm : int\n",
    "\t\tinteger value of M in the SK function. Outside accumulations of spectra.\n",
    "\td : float\n",
    "\t\tshape parameter d in the SK function. Usually 1 but can be empirically determined.\n",
    "\t\n",
    "\tReturns\n",
    "\t-----------\n",
    "\tout : ndarray\n",
    "\t\tSpectrum of SK values.\n",
    "\t\"\"\"\n",
    "\tsk_est = ((m*n*d+1)/(m-1))*(((m*s2)/(s1**2))-1)                     \n",
    "\treturn sk_est\n",
    "\n",
    "\n",
    "#multiscale variant\n",
    "#only takes n=1 for now\n",
    "#takes sum1 and sum2 as arguments rather than computing inside\n",
    "@jit(parallel=True)\n",
    "def ms_SK_EST(s1,s2,m,n=1,d=1):\n",
    "\t\"\"\"\n",
    "\tMulti-scale Variant of SK_EST.\n",
    "\n",
    "\tParameters\n",
    "\t-----------\n",
    "\ts1 : ndarray\n",
    "\t\t2-dimensional array of power values. Shape (Num Channels , Num Raw Spectra)\n",
    "\n",
    "\ts2 : ndarray\n",
    "\t\t2-dimensional array of squared power values. Shape (Num Channels , Num Raw Spectra)\n",
    "\n",
    "\tm : int\n",
    "\t\tinteger value of M in the SK function. Outside accumulations of spectra.\n",
    "\n",
    "\tms0 : int\n",
    "\t\taxis 0 multiscale\n",
    "\t\n",
    "\tms1 : int\n",
    "\t\taxis 1 multiscale\n",
    "\t\n",
    "\tReturns\n",
    "\t-----------\n",
    "\tout : ndarray\n",
    "\t\tSpectrum of SK values.\n",
    "\t\"\"\"\n",
    "\t\n",
    "                 #((m*n*d+1)/(m-1))*(((m*sum2)/(sum1**2))-1)\n",
    "\tsk_est = ((m*n*d+1)/(m-1))*(((m*s2)/(s1**2))-1)\n",
    "\t#print(sk_est)\n",
    "\treturn sk_est\n",
    "\n",
    "\n",
    "def master_SK_EST(data,SK_M,m,n=1,d=1):\n",
    "\t\n",
    "\n",
    "\tnum_skbins = data.shape[1]//SK_M\n",
    "\n",
    "\tdata = np.abs(np.reshape(data,(data.shape[0],-1,SK_M,data.shape[2])))**2\n",
    "\n",
    "\n",
    "\ts1 = np.sum(data,axis=2)\n",
    "\ts2 = np.sum(data**2,axis=2)\n",
    "\n",
    "\tspect_block = np.mean(data,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def upperRoot(x, moment_2, moment_3, p):\n",
    "\tupper = np.abs( (1 - sp.special.gammainc( (4 * moment_2**3)/moment_3**2, (-(moment_3-2*moment_2**2)/moment_3 + x)/(moment_3/2/moment_2)))-p)\n",
    "\treturn upper\n",
    "\n",
    "#helps calculate lower SK threshold\n",
    "def lowerRoot(x, moment_2, moment_3, p):\n",
    "\tlower = np.abs(sp.special.gammainc( (4 * moment_2**3)/moment_3**2, (-(moment_3-2*moment_2**2)/moment_3 + x)/(moment_3/2/moment_2))-p)\n",
    "\treturn lower\n",
    "\n",
    "#fully calculates upper and lower thresholds\n",
    "#M = SK_ints\n",
    "#default p = PFA = 0.0013499 corresponds to 3sigma excision\n",
    "def SK_thresholds(M, N = 1, d = 1, p = 0.0013499):\n",
    "\t\"\"\"\n",
    "\tDetermine SK thresholds numerically.\n",
    "\n",
    "\tParameters\n",
    "\t-----------\n",
    "\tm : int\n",
    "\t\tinteger value of M in the SK function. Outside accumulations of spectra.\n",
    "\tn : int\n",
    "\t\tinteger value of N in the SK function. Inside accumulations of spectra.\n",
    "\td : float\n",
    "\t\tshape parameter d in the SK function. Usually 1 but can be empirically determined.\n",
    "\tp : float\n",
    "\t\tProb of false alarm. 0.0013499 corresponds to 3-sigma excision.\n",
    "\t\n",
    "\tReturns\n",
    "\t-----------\n",
    "\tout : tuple\n",
    "\t\tTuple of (lower threshold, upper threshold).\n",
    "\t\"\"\"\n",
    "\n",
    "\tNd = N * d\n",
    "\t#Statistical moments\n",
    "\tmoment_1 = 1\n",
    "\tmoment_2 = float(( 2*(M**2) * Nd * (1 + Nd) )) / ( (M - 1) * (6 + 5*M*Nd + (M**2)*(Nd**2)) )\n",
    "\tmoment_3 = float(( 8*(M**3)*Nd * (1 + Nd) * (-2 + Nd * (-5 + M * (4+Nd))) )) / ( ((M-1)**2) * (2+M*Nd) *(3+M*Nd)*(4+M*Nd)*(5+M*Nd))\n",
    "\tmoment_4 = float(( 12*(M**4)*Nd*(1+Nd)*(24+Nd*(48+84*Nd+M*(-32+Nd*(-245-93*Nd+M*(125+Nd*(68+M+(3+M)*Nd)))))) )) / ( ((M-1)**3)*(2+M*Nd)*(3+M*Nd)*(4+M*Nd)*(5+M*Nd)*(6+M*Nd)*(7+M*Nd) )\n",
    "\t#Pearson Type III Parameters\n",
    "\tdelta = moment_1 - ( (2*(moment_2**2))/moment_3 )\n",
    "\tbeta = 4 * ( (moment_2**3)/(moment_3**2) )\n",
    "\talpha = moment_3 / (2 * moment_2)\n",
    "\tbeta_one = (moment_3**2)/(moment_2**3)\n",
    "\tbeta_two = (moment_4)/(moment_2**2)\n",
    "\terror_4 = np.abs( (100 * 3 * beta * (2+beta) * (alpha**4)) / (moment_4 - 1) )\n",
    "\tkappa = float( beta_one*(beta_two+3)**2 ) / ( 4*(4*beta_two-3*beta_one)*(2*beta_two-3*beta_one-6) )\n",
    "\tprint('kappa: {}'.format(kappa))\n",
    "\tx = [1]\n",
    "\tprint(x, moment_2, moment_3, p)\n",
    "\tupperThreshold = sp.optimize.newton(upperRoot, x[0], args = (moment_2, moment_3, p))\n",
    "\tlowerThreshold = sp.optimize.newton(lowerRoot, x[0], args = (moment_2, moment_3, p))\n",
    "\treturn lowerThreshold, upperThreshold\n",
    "\n",
    "\n",
    "\t\n",
    "\n",
    "\n",
    "def averager(data,m):\n",
    "\t\"\"\"\n",
    "\taverage of data\n",
    "\t\"\"\"\n",
    "\tstep1_p0 = np.reshape(data[:,:,0], (data.shape[0],-1,m)) # polarization 1\n",
    "\tstep1_p1 = np.reshape(data[:,:,1], (data.shape[0],-1,m)) # 2\n",
    "\tstep2_p0 = np.expand_dims(np.mean(step1_p0,axis=2),axis=2)\n",
    "\tstep2_p1 = np.expand_dims(np.mean(step1_p1,axis=2),axis=2)\n",
    "\treturn np.concatenate((step2_p0,step2_p1),axis=2)           \n",
    "                  \n",
    "\n",
    "def stdever(data,m):\n",
    "\t\"\"\"\n",
    "\tstandard deviation of data\n",
    "\t\"\"\"\n",
    "\tstep1_p0 = np.reshape(data[:,:,0], (data.shape[0],-1,m)) # polarization 1\n",
    "\tstep1_p1 = np.reshape(data[:,:,1], (data.shape[0],-1,m)) # 2\n",
    "\tstep2_p0 = np.expand_dims(np.mean(step1_p0,axis=2),axis=2)\n",
    "\tstep2_p1 = np.expand_dims(np.mean(step1_p1,axis=2),axis=2)\n",
    "\treturn np.concatenate((step2_p0,step2_p1),axis=2)    \n",
    "\n",
    "\n",
    "def iqrm_power(data, radius, threshold):\n",
    "\tm = 512 # constant\n",
    "\tavg_pre = averager(np.abs(data)**2,m)\n",
    "\tdata = np.abs(data)**2\n",
    "\tflag_chunk = np.zeros(data.shape)\n",
    "\tfor i in tqdm(range(data.shape[2])): # iterate through polarizations\n",
    "\t\tfor j in range(data.shape[0]): # iterate through channels\n",
    "\t\t\tflag_chunk[j,:,i] = iqrm.iqrm_mask(data[j,:,i], radius = radius, threshold = threshold)[0]\n",
    "    \n",
    "#     avg_post = \n",
    "\treturn flag_chunk, avg_pre\n",
    "\n",
    "\n",
    "\n",
    "def iqrm_std(data, radius, threshold, breakdown):\n",
    "\t\"\"\"\n",
    "\tbreakdown must be a factor of the time shape data[1].shape()\n",
    "\t\"\"\"\n",
    "\tm = 512 # constant\n",
    "\tavg_pre = averager(np.abs(data)**2, m)\n",
    "# \tdata_pol0 = stdever(np.abs(data[:,:,0])**2, breakdown) # make it a stdev\n",
    "# # \tshape=np.expand_dims(shape, axis=2)\n",
    "# \tflag_chunk = np.zeros((*data_pol0.shape[:2], 2))\n",
    "# \tprint('Data shape: {} || block size: {}'.format(flag_chunk.shape,flag_chunk.nbytes))\n",
    "    \n",
    "\tdata = stdever(np.abs(data)**2, breakdown)\n",
    "\tflag_chunk = np.zeros(data.shape)\n",
    "\tprint('Flag shape: {} || block size: {}'.format(flag_chunk.shape,flag_chunk.nbytes))\n",
    "\tfor i in tqdm(range(data.shape[2])): # iterate through polarizations\n",
    "\t\tfor j in range(data.shape[0]): # iterate through channels\n",
    "\t\t\tflag_chunk[j,:,i] = iqrm.iqrm_mask(data[j,:,i], radius = radius, threshold = threshold)[0]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "# \tfor j in range(data_pol0.shape[0]): # iterate through channels\n",
    "# \t\tflag_chunk[j,:,0] = iqrm.iqrm_mask(data_pol0[j,:], radius = radius, threshold = threshold)[0]\n",
    "# \tdata_pol1 = stdever(np.abs(data[:,:,1])**2, breakdown) # make it a stdev\n",
    "# \tfor j in range(data_pol1.shape[0]): # iterate through channels\n",
    "# \t\tflag_chunk[j,:,1] = iqrm.iqrm_mask(data_pol1[j,:], radius = radius, threshold = threshold)[0]\n",
    "\n",
    "\treturn flag_chunk, avg_pre\n",
    "\n",
    "#test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kait)",
   "language": "python",
   "name": "kait"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
